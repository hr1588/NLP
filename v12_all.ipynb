{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9g0wAfPwsp3nqfKm+xT0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hr1588/NLP/blob/main/v12_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 로드 (전체 데이터 사용 - ontonote5 / english_v12)"
      ],
      "metadata": {
        "id": "cnSCvD0NvQoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict"
      ],
      "metadata": {
        "id": "uDh8nflyjTPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v12_dataset = load_dataset(\"conll2012_ontonotesv5\", 'english_v12')\n",
        "v12_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WJEzZnqi3ma",
        "outputId": "ecbf266c-624a-4f3e-963a-ef2a6776211b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 10539\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 1370\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document_id', 'sentences'],\n",
              "        num_rows: 1200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v12_dataset['train']['sentences'][0][0]['words']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PQ1C_pH8pjcs",
        "outputId": "f293ab7d-e8ce-492f-a4e5-f1694cbb8b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What', 'kind', 'of', 'memory', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split_name in v12_dataset.keys():\n",
        "    print(f\"{split_name}: {v12_dataset[split_name].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv5D7Ac2uFql",
        "outputId": "6d2794cf-98b5-4e20-e102-2ed3ac725f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (10539, 2)\n",
            "validation: (1370, 2)\n",
            "test: (1200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요한 데이터만 추출"
      ],
      "metadata": {
        "id": "052Yi4zI9Jtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_array = np.array(v12_dataset['train']['sentences'])\n",
        "val_array = np.array(v12_dataset['validation']['sentences'])\n",
        "test_array = np.array(v12_dataset['test']['sentences'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRoex3j4qOq0",
        "outputId": "fd6df103-bed3-4411-dbc0-897a13850cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-036c1ab23748>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_array = np.array(v12_dataset['train']['sentences'])\n",
            "<ipython-input-7-036c1ab23748>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  val_array = np.array(v12_dataset['validation']['sentences'])\n",
            "<ipython-input-7-036c1ab23748>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  test_array = np.array(v12_dataset['test']['sentences'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_array[0][0]['words']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRsFFUULzqQM",
        "outputId": "b66eb1ad-4035-4579-8d4e-5f91a925f20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What', 'kind', 'of', 'memory', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define extract_values function\n",
        "def extract_values(list_of_dicts):\n",
        "    return [{'words': d['words'], 'tags': d['named_entities']} for d in list_of_dicts]"
      ],
      "metadata": {
        "id": "i8jwWzYm5zD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract values using map\n",
        "train_values = list(map(extract_values, train_array))\n",
        "val_values = list(map(extract_values, val_array))\n",
        "test_values = list(map(extract_values, test_array))"
      ],
      "metadata": {
        "id": "hAobaS5puH86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_values[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX6NJ127p9Vy",
        "outputId": "b1caca9d-d05d-4bca-da57-aa00b0a1a5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'words': ['What', 'kind', 'of', 'memory', '?'], 'tags': [0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5SX7XcItgpN",
        "outputId": "28aa65ca-8a2b-4aab-b7cf-88a886dd1e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10539"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7rbzBmctQGt",
        "outputId": "33c366f8-679d-48c8-9661-83f600ec8c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "train_dict = [{\"words\": item[\"words\"], \"tags\": item[\"tags\"]} for sublist in train_values for item in sublist]\n",
        "val_dict = [{\"words\": item[\"words\"], \"tags\": item[\"tags\"]} for sublist in val_values for item in sublist]\n",
        "test_dict = [{\"words\": item[\"words\"], \"tags\": item[\"tags\"]} for sublist in test_values for item in sublist]\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"words\": [item[\"words\"] for item in train_dict], \"tags\": [item[\"tags\"] for item in train_dict]})\n",
        "val_dataset = Dataset.from_dict({\"words\": [item[\"words\"] for item in val_dict], \"tags\": [item[\"tags\"] for item in val_dict]})\n",
        "test_dataset = Dataset.from_dict({\"words\": [item[\"words\"] for item in test_dict], \"tags\": [item[\"tags\"] for item in test_dict]})\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"val\": val_dataset,\n",
        "    \"test\": test_dataset\n",
        "})"
      ],
      "metadata": {
        "id": "SkFEb76Otp26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42E4pe7uUyI",
        "outputId": "6a5babc4-e974-4f99-8315-f7f567239717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['words', 'tags'],\n",
              "        num_rows: 115812\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['words', 'tags'],\n",
              "        num_rows: 15680\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['words', 'tags'],\n",
              "        num_rows: 12217\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each_length = []\n",
        "\n",
        "for i in range(len(train_values)):\n",
        "    for j in range(len(train_values[i])):\n",
        "        each_length.append(len(train_values[j]))"
      ],
      "metadata": {
        "id": "lNziQs1XuP8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(each_length) # 길이 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO5EIVP5tps-",
        "outputId": "719b526c-230e-4ae1-edb9-beb7dda3d001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115812"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each_length[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v35EXT5Mu_y9",
        "outputId": "728caf4d-74ee-4f12-ccee-c77eeaa6b597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 정제"
      ],
      "metadata": {
        "id": "r_I4s_KtvTBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feature의 key, value 확인"
      ],
      "metadata": {
        "id": "ChtGwC4o9iwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in dataset_dict['train'].features.items():\n",
        "    print(f\"{key} : {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xeg-kSBKvUJl",
        "outputId": "5a89c0a3-7abd-45f1-ecb9-59b9bd39b3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words : Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
            "tags : Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "element = dataset_dict['train'][0]\n",
        "for key, value in element.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z06ZJXwcvaJa",
        "outputId": "7aff40af-b594-44dc-c98f-691280aa299c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words: ['What', 'kind', 'of', 'memory', '?']\n",
            "tags: [0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = dataset_dict['train'].features['tags'].feature\n",
        "tags # 현재 태그 존재 X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo5XFEY3vfTC",
        "outputId": "5cb2895c-f9d8-4f71-8ae6-61187ff32cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='int64', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v12_tags = v12_dataset['train'].features['sentences'][0]['named_entities']\n",
        "v12_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d33782jNvjhz",
        "outputId": "0072985a-483a-45f0-b8ff-f5adb00479c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PERSON', 'I-PERSON', 'B-NORP', 'I-NORP', 'B-FAC', 'I-FAC', 'B-ORG', 'I-ORG', 'B-GPE', 'I-GPE', 'B-LOC', 'I-LOC', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'B-MONEY', 'I-MONEY', 'B-QUANTITY', 'I-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'B-CARDINAL', 'I-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-LAW', 'I-LAW', 'B-LANGUAGE', 'I-LANGUAGE'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(v12_tags.feature.names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRf2HMx2v4Lj",
        "outputId": "c79f1d7b-c302-4c43-c6f5-b207953448f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(v12_tags.feature.names)\n",
        "\n",
        "from datasets import DatasetDict, ClassLabel\n",
        "ner_labels = ClassLabel(names=v12_tags.feature.names, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "trZsxbWYv-6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split in ['train', 'val', 'test']:\n",
        "    dataset_dict[split].features['tags'].feature = ner_labels"
      ],
      "metadata": {
        "id": "SPs8ecrHwImI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = dataset_dict['train'].features['tags'].feature\n",
        "tags # 태그 삽입 완료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1StK3f1mwM5V",
        "outputId": "a77177f9-6214-43b1-a426-d23ba6202344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(names=['O', 'B-PERSON', 'I-PERSON', 'B-NORP', 'I-NORP', 'B-FAC', 'I-FAC', 'B-ORG', 'I-ORG', 'B-GPE', 'I-GPE', 'B-LOC', 'I-LOC', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'B-TIME', 'I-TIME', 'B-PERCENT', 'I-PERCENT', 'B-MONEY', 'I-MONEY', 'B-QUANTITY', 'I-QUANTITY', 'B-ORDINAL', 'I-ORDINAL', 'B-CARDINAL', 'I-CARDINAL', 'B-EVENT', 'I-EVENT', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'B-LAW', 'I-LAW', 'B-LANGUAGE', 'I-LANGUAGE'], id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## str 파생변수 제작"
      ],
      "metadata": {
        "id": "6CLuqClv9om2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tag_names(batch):\n",
        "    return{\"ner_tags_str\" : [tags.int2str(idx) for idx in batch['tags']]}"
      ],
      "metadata": {
        "id": "Y_Ic5OKOwUtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_dataset = dataset_dict.map(create_tag_names)\n",
        "ner_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "4db8f9be494c4f0e92fe579fa25cd113",
            "1e5928856552489a8ff905f2baeda214",
            "c46dbf77cd5342fd9056ece9168614fe",
            "89c47c932d714ddf82b9211972354903",
            "794da5a2a3f0430cad4c29b272bfbbfb",
            "1d0d086ae14549ce82c520085bcf58e4",
            "b28ab1f910a3439e84df41106822c3f8",
            "116b843685b7431386d79206f5ddf1cc",
            "2bf2afb1217541aa9059a33f2eaa349c",
            "43fe6bafbe744deb95c720424530f9ce",
            "75978945b9ae4743b42070fa301e21ba",
            "dfb2cc9b8705456b9aee76704846648c",
            "78b16aeed69b48e9a579532c6550a30b",
            "d393631e535f41119d48208fca7d544d",
            "ffe230829c8e4dfd8875e408bfc2fd35",
            "19553c50ed094c0698a34777faecd2a1",
            "1d90de97588e465a93d35ec38fadfce2",
            "c33f29a52ed84c8da860c17bfaeb3b68",
            "c3865fbe7f3c470a814cca6b0625a36c",
            "7bdac36d217d40b8809456ca207bfb1c",
            "3a2ba315cff1462e92aad906227e0d84",
            "9d4d68edd6dc4ccc9b59cec54ffff62e",
            "a86aba5234774d208ccdd7c9a9d1e73e",
            "5e594c368e2a40fa81d195516e53432d",
            "f33e730d5c7d48898d9ca86d0bfd9091",
            "6380c2a752444946ab7ec403c618c8bc",
            "67cc37d2130c4196aafe9cf95bfe86f2",
            "e60cef811bdf423a8d3be3af20e81384",
            "fc4d84f28faf4b39865083a2a52b9dae",
            "ab2dcde519fd43ddad8c036d89c6fbc7",
            "8817872ec35a4037b0d07fa1296ac583",
            "40519a7d20714c72a0ebb8c4c6655b87",
            "2f1f6709918445c2b5467cf8d28a24b5"
          ]
        },
        "id": "jzEsxu-XwaJ1",
        "outputId": "664c81dd-36e4-42bf-a3c0-8b069cfe0ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/115812 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4db8f9be494c4f0e92fe579fa25cd113"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15680 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb2cc9b8705456b9aee76704846648c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12217 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a86aba5234774d208ccdd7c9a9d1e73e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['words', 'tags', 'ner_tags_str'],\n",
              "        num_rows: 115812\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['words', 'tags', 'ner_tags_str'],\n",
              "        num_rows: 15680\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['words', 'tags', 'ner_tags_str'],\n",
              "        num_rows: 12217\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ner tag 빈도 확인"
      ],
      "metadata": {
        "id": "VQwx4mj89DrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "split2freqs = defaultdict(Counter)\n",
        "\n",
        "for split, dataset in ner_dataset.items():\n",
        "    for row in dataset['ner_tags_str']:\n",
        "        for tag in row:\n",
        "            if tag.startswith('B'):\n",
        "                tag_type = tag.split(\"-\")[1]\n",
        "                split2freqs[split][tag_type] += 1\n",
        "\n",
        "pd.DataFrame.from_dict(split2freqs, orient = 'index').T.sort_values(['train','val','test'], ascending = [False, False, False])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "8_6M6IC2wdOd",
        "outputId": "1a31eaba-d418-4c0c-f814-841562979d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             train   val  test\n",
              "ORG          24163  3798  2002\n",
              "PERSON       22035  3163  2134\n",
              "GPE          21938  3649  2546\n",
              "DATE         18791  3208  1787\n",
              "CARDINAL     10901  1720  1005\n",
              "NORP          9341  1277   990\n",
              "MONEY         5217   853   355\n",
              "PERCENT       3802   656   408\n",
              "ORDINAL       2195   335   207\n",
              "LOC           2160   316   215\n",
              "TIME          1703   361   225\n",
              "WORK_OF_ART   1279   202   169\n",
              "QUANTITY      1240   190   153\n",
              "FAC           1158   133   149\n",
              "EVENT         1009   179    85\n",
              "PRODUCT        992   214    90\n",
              "LAW            459    65    44\n",
              "LANGUAGE       355    35    22"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69a7c0ee-2498-4c1f-ae62-cfc7433e742f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>val</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>24163</td>\n",
              "      <td>3798</td>\n",
              "      <td>2002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERSON</th>\n",
              "      <td>22035</td>\n",
              "      <td>3163</td>\n",
              "      <td>2134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GPE</th>\n",
              "      <td>21938</td>\n",
              "      <td>3649</td>\n",
              "      <td>2546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <td>18791</td>\n",
              "      <td>3208</td>\n",
              "      <td>1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CARDINAL</th>\n",
              "      <td>10901</td>\n",
              "      <td>1720</td>\n",
              "      <td>1005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NORP</th>\n",
              "      <td>9341</td>\n",
              "      <td>1277</td>\n",
              "      <td>990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MONEY</th>\n",
              "      <td>5217</td>\n",
              "      <td>853</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERCENT</th>\n",
              "      <td>3802</td>\n",
              "      <td>656</td>\n",
              "      <td>408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORDINAL</th>\n",
              "      <td>2195</td>\n",
              "      <td>335</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>2160</td>\n",
              "      <td>316</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TIME</th>\n",
              "      <td>1703</td>\n",
              "      <td>361</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WORK_OF_ART</th>\n",
              "      <td>1279</td>\n",
              "      <td>202</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUANTITY</th>\n",
              "      <td>1240</td>\n",
              "      <td>190</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAC</th>\n",
              "      <td>1158</td>\n",
              "      <td>133</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EVENT</th>\n",
              "      <td>1009</td>\n",
              "      <td>179</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRODUCT</th>\n",
              "      <td>992</td>\n",
              "      <td>214</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAW</th>\n",
              "      <td>459</td>\n",
              "      <td>65</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LANGUAGE</th>\n",
              "      <td>355</td>\n",
              "      <td>35</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a7c0ee-2498-4c1f-ae62-cfc7433e742f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69a7c0ee-2498-4c1f-ae62-cfc7433e742f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69a7c0ee-2498-4c1f-ae62-cfc7433e742f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 3가지 데이터 모두 비슷한 추세를 보이고 있음을 확인"
      ],
      "metadata": {
        "id": "LbZuzsnN9vGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "84aNtkgdwy0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -qqq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFy3pOe1wnwt",
        "outputId": "d7eb941c-a37d-4056-cb00-29ebc185fc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import TrainingArguments\n",
        "from transformers import XLMRobertaForTokenClassification\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import Trainer\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from seqeval.metrics import f1_score, accuracy_score\n",
        "\n",
        "bert_model_name = 'bert-base-cased'\n",
        "xlmr_model_name = 'xlm-roberta-base'\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
        "\n",
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "    config_class = XLMRobertaConfig\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        # 바디 로드\n",
        "        self.roberta = RobertaModel(config, add_pooling_layer=False) \n",
        "\n",
        "        # 토큰 분류 헤드 준비\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "       \n",
        "        self.init_weights() # 가중치 로드 및 초기화\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
        "                labels=None, **kwargs):\n",
        "       \n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
        "                               token_type_ids=token_type_ids, **kwargs) \n",
        "        \n",
        "        sequence_output = self.dropout(outputs[0])\n",
        "        logits = self.classifier(sequence_output)\n",
        "        \n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        \n",
        "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
        "                                     hidden_states=outputs.hidden_states, \n",
        "                                     attentions=outputs.attentions)\n",
        "\n",
        "\n",
        "index2tag = {idx: tag for idx, tag in enumerate(v12_tags.feature.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(v12_tags.feature.names)}\n",
        "\n",
        "\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
        "                                         num_labels=len(tags.names),\n",
        "                                         id2label=index2tag, label2id=tag2index)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "xlmr_model = (XLMRobertaForTokenClassification\n",
        "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
        "              .to(device))\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = xlmr_tokenizer(examples[\"words\"], truncation=True, \n",
        "                                      is_split_into_words=True)\n",
        "    labels = []\n",
        "    for idx, label in enumerate(examples[\"tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None or word_idx == previous_word_idx:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(label[word_idx])\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "def encode_dataset(corpus):\n",
        "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
        "                      remove_columns=['tags', 'words'])\n",
        "\n",
        "data_encoded = encode_dataset(ner_dataset)\n",
        "\n",
        "def align_predictions(predictions, labels):\n",
        "    preds = np.argmax(predictions, axis=2)\n",
        "    batch_size, seq_len = preds.shape\n",
        "    labels_list, preds_list = [], []\n",
        "\n",
        "    for batch_idx in range(batch_size):\n",
        "        example_labels, example_preds = [], []\n",
        "        for seq_idx in range(seq_len):\n",
        "            # 레이블 IDs = -100 무시\n",
        "            if labels[batch_idx, seq_idx] != -100:\n",
        "                example_labels.append(index2tag[labels[batch_idx][seq_idx]])\n",
        "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "\n",
        "        labels_list.append(example_labels)\n",
        "        preds_list.append(example_preds)\n",
        "\n",
        "    return preds_list, labels_list\n",
        "\n",
        "num_epochs = 2\n",
        "batch_size = 16  \n",
        "logging_steps = len(data_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
        "    per_device_train_batch_size=batch_size, \n",
        "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\", \n",
        "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
        "    logging_steps=logging_steps, push_to_hub=False)\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441,
          "referenced_widgets": [
            "461492103e66481c85446a7effe0117a",
            "8b25b82119be47c99105dc45892fdc97",
            "e37e5d6f50564423ad0d215a72399946",
            "65ee6dd750194cbb9a836a19022a3e06",
            "3a0609e0688d45dea0f04afd8e019276",
            "b4f3e6271b8c4220ab244db63bae3dfa",
            "4079da03a74449ab83e1363c1eccf35d",
            "fc37ee3438924e7eb73fbd7ea81a2438",
            "29a92aad359e4090b426480fb9eede7c",
            "75fbe65b612f42e8b613f3a2975a3df4",
            "c736aaefe7ea4c928c96eed45bafd96b",
            "8ba0af2b79b64728bed9e50d7bdcfd7a",
            "8d9105b0e1cc411f8dd837f5e0a903ff",
            "b1cdffd315754b4aaa47cdfb2ae12137",
            "2954c807370245ccbbb0a32d508dcf9b",
            "b903a54cf5b34ec4a5aed883fdc12db0",
            "43238ed4d7014301a76d56ffad03ccff",
            "0c8605757e1448d58926e6473a29a8da",
            "1099801c60214873b974c90c8fb62d6e",
            "ddd38fc5ffdb4e3c8325d7b42f82a98e",
            "a66f623feb494a588321f09bc797632c",
            "f5834cce5b1f41b1a918bdb3878b1c70",
            "f89bcf7e055b4fcf8815c9e860a26214",
            "bf9de41e442a40d2ac6774d3661ddadb",
            "0818376de9e14c5bad4d3ac1cacad1ef",
            "bd2d953b4c284149b84b73c1c8c1e0d4",
            "96de696a307b4d7697f8fe04644350d9",
            "f9342cf961f047f78b5ab373abae18bc",
            "0d8efcfc52e84a1c882e04c05281c740",
            "4fd50d1253bc4c7cbc5e2a89c4b16524",
            "ece46053b6df4e7495aa258ef5661ca7",
            "710063dd370345f5be5cff565423183a",
            "ef8547961aa242d19f4453794f01922d",
            "de9ce893c47b4b20baa94920ef964f5e",
            "6b42c5c0c7084e19b2b7834624b09e39",
            "62eebdf3ef354bd399763c3fd4f2d647",
            "91f0a8a936e04612935b1ce33093dde4",
            "1fd70fbdea8c49819a1e024e570f3264",
            "77fe29d3e4964fd1bb97b70c77bd6ff1",
            "81189f2a153c4a43981fec41cfe3ef93",
            "3a571e2280f94f46887bfc386cc17e9d",
            "df342a53bf7d4e86a187ae407704028b",
            "d668305a6c2b43f89d2f0f90298f4689",
            "d6ddf05f476d451eb463ba67ec7af500",
            "20d673087383475087ff3923d52136c1",
            "2ef4e5bf702c4b70b7bc15b464614b9c",
            "0e3f32c9cd2b4adcaa14061d448cd3cf",
            "2082d2784bce4cc883e1ad064f0f0a85",
            "0dab98c5e94f451890db6eb005f5436e",
            "444d23be197a43d59237dfba6c4bbfba"
          ]
        },
        "id": "MwyG7W80w3jx",
        "outputId": "035ee134-ed2e-45eb-aee2-597bcc0518ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    y_pred, y_true = align_predictions(eval_pred.predictions, \n",
        "                                       eval_pred.label_ids)\n",
        "    return {\"f1\": f1_score(y_true, y_pred)}\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)\n",
        "\n",
        "def model_init():\n",
        "    return (XLMRobertaForTokenClassification\n",
        "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
        "            .to(device))\n",
        "\n",
        "trainer = Trainer(model_init=model_init, args=training_args, \n",
        "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
        "                  train_dataset=data_encoded[\"train\"],\n",
        "                  eval_dataset=data_encoded[\"val\"], \n",
        "                  tokenizer=xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "Fm1vdQr8zIA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "tf-BBz6wzIkq",
        "outputId": "412e3998-bc78-4d4c-81fa-fb28a23fe5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7621' max='14478' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 7621/14478 38:07 < 34:18, 3.33 it/s, Epoch 1.05/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.104400</td>\n",
              "      <td>0.084080</td>\n",
              "      <td>0.842507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2555\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 코랩 무료 버전에서는 1 epoch만 확인"
      ],
      "metadata": {
        "id": "XIxbnA7y931N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-BgnEmKzL8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}